// ============================================================================
// SETUP: ML Anomaly Detection para PostgreSQL Monitoring (v3 Enhanced)
// ============================================================================
// Este script crea la infraestructura para detecci√≥n de anomal√≠as con ML
// usando series_decompose_anomalies() en Fabric Real-Time Intelligence
// ============================================================================
// 
// üî¥ MEJORAS v3:
// - HourOfDay y DayOfWeek para detectar patrones temporales
// - Desglose de operaciones (SELECT, WRITE, DDL, Privilege)
// - UniqueUsers para detectar cardinalidad anormal
// - PrivilegeOps para rastrear GRANTs/REVOKEs sospechosos
// ============================================================================

// ============================================================================
// PASO 1: Crear tabla de m√©tricas agregadas (destino) - VERSI√ìN MEJORADA
// ============================================================================

.create table postgres_activity_metrics (
    Timestamp: datetime,
    ServerName: string,
    HourOfDay: int,              // 0-23 para patrones horarios
    DayOfWeek: int,              // 0=Dom, 1=Lun, ..., 6=Sab
    ActivityCount: long,
    AuditLogs: long,
    Errors: long,
    Connections: long,
    UniqueUsers: long,           // Usuarios distintos activos
    SelectOps: long,             // Operaciones de lectura
    WriteOps: long,              // INSERT/UPDATE/DELETE
    DDLOps: long,                // CREATE/DROP/ALTER
    PrivilegeOps: long           // GRANT/REVOKE (alertas de escalada)
)


// ============================================================================
// PASO 2: Crear funci√≥n de agregaci√≥n MEJORADA (m√°s dimensiones)
// ============================================================================

.create-or-alter function postgres_activity_metrics_transform() {
    bronze_pssql_alllogs_nometrics
    | where category == "PostgreSQLLogs"
    | extend 
        HourOfDay = hourofday(EventProcessedUtcTime),
        DayOfWeek = dayofweek(EventProcessedUtcTime) / 1d,
        UserName = extract(@"user=([^\s,]+)", 1, message)
    | summarize 
        ActivityCount = count(),
        AuditLogs = countif(message contains "AUDIT:"),
        Errors = countif(errorLevel in ("ERROR", "FATAL", "PANIC")),
        Connections = countif(message contains "connection authorized"),
        UniqueUsers = dcount(UserName),
        SelectOps = countif(message has_any ("SELECT", "COPY", ",READ,")),
        WriteOps = countif(message has_any ("INSERT", "UPDATE", "DELETE", ",WRITE,")),
        DDLOps = countif(message has_any ("CREATE", "DROP", "ALTER TABLE", "ALTER INDEX")),
        PrivilegeOps = countif(message has_any ("GRANT", "REVOKE", "ALTER ROLE", "CREATE ROLE"))
        by ServerName = LogicalServerName, 
           Timestamp = bin(EventProcessedUtcTime, 5m),
           HourOfDay = hourofday(EventProcessedUtcTime),
           DayOfWeek = toint(dayofweek(EventProcessedUtcTime) / 1d)
    | project Timestamp, ServerName, HourOfDay, DayOfWeek, 
              ActivityCount, AuditLogs, Errors, Connections,
              UniqueUsers, SelectOps, WriteOps, DDLOps, PrivilegeOps
}


// ============================================================================
// PASO 3: Crear Update Policy (pipeline autom√°tico)
// ============================================================================

.alter table postgres_activity_metrics policy update 
@'[{"IsEnabled": true, "Source": "bronze_pssql_alllogs_nometrics", "Query": "postgres_activity_metrics_transform()", "IsTransactional": false, "PropagateIngestionProperties": false}]'


// ============================================================================
// PASO 4: Popular tabla con datos hist√≥ricos (30 d√≠as para entrenamiento)
// ============================================================================
// El ML necesita hist√≥rico para aprender el baseline normal
// SOLO ejecutar UNA VEZ despu√©s de crear la tabla

.set-or-append postgres_activity_metrics <|
    bronze_pssql_alllogs_nometrics
    | where EventProcessedUtcTime >= ago(30d)
    | where category == "PostgreSQLLogs"
    | extend 
        HourOfDay = hourofday(EventProcessedUtcTime),
        DayOfWeek = toint(dayofweek(EventProcessedUtcTime) / 1d),
        UserName = extract(@"user=([^\s,]+)", 1, message)
    | summarize 
        ActivityCount = count(),
        AuditLogs = countif(message contains "AUDIT:"),
        Errors = countif(errorLevel in ("ERROR", "FATAL", "PANIC")),
        Connections = countif(message contains "connection authorized"),
        UniqueUsers = dcount(UserName),
        SelectOps = countif(message has_any ("SELECT", "COPY", ",READ,")),
        WriteOps = countif(message has_any ("INSERT", "UPDATE", "DELETE", ",WRITE,")),
        DDLOps = countif(message has_any ("CREATE", "DROP", "ALTER TABLE")),
        PrivilegeOps = countif(message has_any ("GRANT", "REVOKE", "ALTER ROLE"))
        by ServerName = LogicalServerName, 
           Timestamp = bin(EventProcessedUtcTime, 5m),
           HourOfDay = hourofday(EventProcessedUtcTime),
           DayOfWeek = toint(dayofweek(EventProcessedUtcTime) / 1d)
    | project Timestamp, ServerName, HourOfDay, DayOfWeek,
              ActivityCount, AuditLogs, Errors, Connections,
              UniqueUsers, SelectOps, WriteOps, DDLOps, PrivilegeOps


// ============================================================================
// PASO 5: Verificar que la tabla se est√° actualizando
// ============================================================================

// Ver √∫ltimos registros
postgres_activity_metrics
| order by Timestamp desc
| take 20;

// Ver estad√≠sticas por servidor
postgres_activity_metrics
| where Timestamp >= ago(24h)
| summarize 
    Records = count(),
    AvgActivity = avg(ActivityCount),
    MaxActivity = max(ActivityCount),
    AvgErrors = avg(Errors)
    by ServerName;


// ============================================================================
// PASO 6: Configurar Anomaly Detector en Fabric UI
// ============================================================================
// Ahora ve a Fabric Real-Time Intelligence:
//
// 1. Abre tu KQL Database
// 2. Click en la tabla "postgres_activity_metrics"
// 3. Click en "Anomaly detection" (bot√≥n superior)
// 4. Configurar:
//    - Table: postgres_activity_metrics
//    - Timestamp column: Timestamp
//    - Value to watch: ActivityCount
//    - Group by dimension: ServerName
//    - Sensitivity: Medium (ajustar despu√©s)
//    - Lookback period: 7 days
// 5. Click "Create"
// 6. Espera 5-10 minutos para que entrene el modelo
//
// ============================================================================


// ============================================================================
// OPCIONAL: Crear m√°s tablas para otras m√©tricas
// ============================================================================

// ----------------------------------------------------------------------------
// M√©trica 2: Errores por Servidor
// ----------------------------------------------------------------------------

.create table postgres_error_metrics (
    Timestamp: datetime,
    ServerName: string,
    ErrorRate: long,
    ErrorTypes: string
)

.create-or-alter function postgres_error_metrics_transform() {
    bronze_pssql_alllogs_nometrics
    | where category == "PostgreSQLLogs"
    | where errorLevel in ("ERROR", "FATAL", "PANIC") or (sqlerrcode != "00000" and sqlerrcode != "")
    | extend ErrorCategory = case(
        message contains "authentication" or message contains "password", "Authentication",
        message contains "permission denied", "Permission",
        message contains "connection", "Connection",
        "Other"
    )
    | summarize 
        ErrorRate = count(),
        ErrorTypes = strcat_array(make_set(ErrorCategory), ", ")
        by ServerName = LogicalServerName, Timestamp = bin(EventProcessedUtcTime, 1m)
    | project Timestamp, ServerName, ErrorRate, ErrorTypes
}

.alter table postgres_error_metrics policy update 
@'[{"IsEnabled": true, "Source": "bronze_pssql_alllogs_nometrics", "Query": "postgres_error_metrics_transform()", "IsTransactional": false, "PropagateIngestionProperties": false}]'

// Popular con hist√≥rico
.set-or-append postgres_error_metrics <|
    bronze_pssql_alllogs_nometrics
    | where EventProcessedUtcTime >= ago(30d)
    | where category == "PostgreSQLLogs"
    | where errorLevel in ("ERROR", "FATAL", "PANIC") or (sqlerrcode != "00000" and sqlerrcode != "")
    | extend ErrorCategory = case(
        message contains "authentication" or message contains "password", "Authentication",
        message contains "permission denied", "Permission",
        message contains "connection", "Connection",
        "Other"
    )
    | summarize 
        ErrorRate = count(),
        ErrorTypes = strcat_array(make_set(ErrorCategory), ", ")
        by ServerName = LogicalServerName, Timestamp = bin(EventProcessedUtcTime, 1m)
    | project Timestamp, ServerName, ErrorRate, ErrorTypes;


// ----------------------------------------------------------------------------
// M√©trica 3: Actividad por Usuario
// ----------------------------------------------------------------------------

.create table postgres_user_metrics (
    Timestamp: datetime,
    UserName: string,
    ServerName: string,
    QueryCount: long,
    SelectQueries: long,
    DestructiveOps: long
)

.create-or-alter function postgres_user_metrics_transform() {
    let sessionInfo = 
    bronze_pssql_alllogs_nometrics
    | where EventProcessedUtcTime >= ago(24h)
    | where message contains "connection authorized" or message contains "connection received"
    | extend UserName = extract(@"user=([^\s,]+)", 1, message)
    | where isnotempty(UserName)
    | summarize User = any(UserName) by processId, LogicalServerName;
    
    bronze_pssql_alllogs_nometrics
    | where category == "PostgreSQLLogs"
    | where message contains "AUDIT:"
    | join kind=leftouter sessionInfo on processId, LogicalServerName
    | where isnotempty(User)
    | extend
        IsSelect = message has_any ("SELECT", "COPY"),
        IsDestructive = message has_any ("DELETE", "UPDATE", "TRUNCATE", "DROP")
    | summarize 
        QueryCount = count(),
        SelectQueries = countif(IsSelect),
        DestructiveOps = countif(IsDestructive)
        by UserName = User, ServerName = LogicalServerName, Timestamp = bin(EventProcessedUtcTime, 1h)
    | project Timestamp, UserName, ServerName, QueryCount, SelectQueries, DestructiveOps
}

.alter table postgres_user_metrics policy update 
@'[{"IsEnabled": true, "Source": "bronze_pssql_alllogs_nometrics", "Query": "postgres_user_metrics_transform()", "IsTransactional": false, "PropagateIngestionProperties": false}]'

// Popular con hist√≥rico (√∫ltimos 7 d√≠as, no 30, para no sobrecargar)
.set-or-append postgres_user_metrics <|
    postgres_user_metrics_transform()
    | where Timestamp >= ago(7d);


// ============================================================================
// TROUBLESHOOTING
// ============================================================================

// Ver si la Update Policy est√° funcionando
.show table postgres_activity_metrics policy update

// Ver errores de ingesta (si la tabla no se actualiza)
.show ingestion failures
| where Table == "postgres_activity_metrics"
| order by FailedOn desc
| take 20;

// Forzar refresh manual (si es necesario)
.refresh table postgres_activity_metrics


// ============================================================================
// CLEANUP (si quieres empezar de cero)
// ============================================================================

// .drop table postgres_activity_metrics ifexists
// .drop table postgres_error_metrics ifexists
// .drop table postgres_user_metrics ifexists
// .drop function postgres_activity_metrics_transform ifexists
// .drop function postgres_error_metrics_transform ifexists
// .drop function postgres_user_metrics_transform ifexists
