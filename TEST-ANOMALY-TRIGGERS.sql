-- ============================================================================
-- SCRIPT DE PRUEBA: Generar AnomalÃ­as para Dashboard PostgreSQL
-- ============================================================================
-- PropÃ³sito: Ejecutar queries que activen las 7 anomalÃ­as del dashboard v3
-- Base de datos: adventureworks (con pgaudit habilitado)
-- Ejecutar con: psql o Azure Data Studio
-- VersiÃ³n: 3.0 (Actualizada 19/01/2026 - Alineada con queries PRODUCTION v3)
-- ============================================================================
--
-- ğŸ“‹ PREREQUISITOS ANTES DE LA DEMO:
-- 1. âœ… ExtensiÃ³n pgaudit instalada: SELECT * FROM pg_extension WHERE extname = 'pgaudit';
-- 2. âœ… pgaudit configurado: SHOW pgaudit.log; (debe ser 'ALL' o incluir 'READ, WRITE')
-- 3. âœ… Diagnostic Settings habilitado en Azure Portal (PostgreSQLLogs enabled)
-- 4. âœ… Event Stream funcionando en Fabric (verificar ingesta)
-- 5. âœ… Tabla bronze_pssql_alllogs_nometrics recibiendo datos
-- 6. âœ… Tabla postgres_activity_metrics creada (para AnomalÃ­a 7 ML)
-- 7. âœ… Dashboard creado con queries de kql-queries-PRODUCTION.kql
-- 8. âœ… Alertas configuradas en Data Activator (opcional para demo)
--
-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
-- ğŸ“Š MAPEO DE TESTS â†’ ANOMALÃAS KQL (kql-queries-PRODUCTION.kql)
-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
-- â”‚ TEST â”‚ ANOMALÃA KQL                    â”‚ THRESHOLD            â”‚ LINEAS KQL â”‚
-- â”œâ”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
-- â”‚  1   â”‚ Potential Data Exfiltration     â”‚ >15 SELECTs / 5 min  â”‚ 26-95      â”‚
-- â”‚  2   â”‚ Mass Destructive Operations     â”‚ >5 ops / 2 min       â”‚ 97-166     â”‚
-- â”‚  3   â”‚ Critical Error Spike            â”‚ (sin threshold/debug)â”‚ 169-245    â”‚
-- â”‚  4   â”‚ Privilege Escalation            â”‚ >3 priv ops / 5 min  â”‚ 252-314    â”‚
-- â”‚  5   â”‚ Cross-Schema Reconnaissance     â”‚ >4 schemas / 10 min  â”‚ 316-374    â”‚
-- â”‚  6   â”‚ Deep Schema Enumeration         â”‚ >10 queries / 5 min  â”‚ 377-455    â”‚
-- â”‚  7   â”‚ ML Baseline Deviation           â”‚ score > 1.5 (ML)     â”‚ 461-498    â”‚
-- â””â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
--
-- ğŸ¯ FLUJO DE LA DEMO (orden recomendado):
-- 1. Ejecutar TEST 1 (Data Exfiltration) â†’ Esperar 1-2 min â†’ Mostrar dashboard
-- 2. Ejecutar TEST 2 (Destructive Ops) â†’ Esperar 1-2 min â†’ Mostrar dashboard
-- 3. Ejecutar TEST 3 (Error Spike) â†’ Esperar 1-2 min â†’ Mostrar dashboard
-- 4. Ejecutar TEST 4 (Privilege Escalation) â†’ Esperar 1-2 min â†’ Mostrar dashboard
-- 5. Ejecutar TEST 5 (Cross-Schema Recon) â†’ Esperar 1-2 min â†’ Mostrar dashboard
-- 6. Ejecutar TEST 6 (Deep Schema Enum) â†’ Esperar 1-2 min â†’ Mostrar dashboard
-- 7. Ejecutar TEST 7 (ML Baseline) â†’ Esperar 5-10 min â†’ Mostrar dashboard
-- 8. (Opcional) TEST AUTH (Brute Force) â†’ Con script externo
--
-- â±ï¸ TIEMPO TOTAL DE DEMO: ~20-30 minutos (2-3 min por test + explicaciÃ³n)
-- ============================================================================

-- ============================================================================
-- TEST 1: ANOMALÃA 1 - ExtracciÃ³n Masiva de Datos (Data Exfiltration)
-- ============================================================================
-- ğŸ“Š Requisito: >15 SELECTs en 5 minutos (Query: kql-queries-PRODUCTION.kql lÃ­neas 26-70)
-- ğŸ¯ Estrategia: Ejecutar 20 SELECTs consecutivos para activar la alerta
-- â±ï¸ Tiempo de ejecuciÃ³n: ~30 segundos
-- ğŸ“ˆ Resultado esperado en dashboard (1-2 min despuÃ©s):
--    - AnomalyType: Potential Data Exfiltration
--    - SelectCount: ~20
--    - TablesAccessed: Lista de tablas accedidas
--    - SampleQueries: Primeras 3 queries ejecutadas
--    - User/Database/SourceHost: Debe mostrar tu informaciÃ³n (no "UNKNOWN")
-- ============================================================================

-- ğŸ” FASE 1: Reconocimiento de tablas del sistema (patrÃ³n tÃ­pico de ataque)
-- Estas queries simulan un atacante explorando la estructura de la base de datos
SELECT * FROM pg_catalog.pg_tables WHERE schemaname = 'public' LIMIT 1;
SELECT * FROM pg_catalog.pg_class WHERE relkind = 'r' LIMIT 1;
SELECT * FROM information_schema.tables WHERE table_schema = 'public' LIMIT 1;
SELECT * FROM information_schema.columns WHERE table_schema = 'public' LIMIT 1;
SELECT * FROM pg_catalog.pg_namespace LIMIT 1;
SELECT * FROM pg_catalog.pg_attribute LIMIT 1;

-- ğŸ“¦ FASE 2: ExtracciÃ³n de datos de negocio (simular exfiltraciÃ³n real)
-- Estas queries simulan un atacante extrayendo datos sensibles
SELECT * FROM sales.customer LIMIT 100;
SELECT * FROM sales.salesorderheader LIMIT 100;
SELECT * FROM sales.salesorderdetail LIMIT 100;
SELECT * FROM person.person LIMIT 100;
SELECT * FROM person.address LIMIT 100;
SELECT * FROM production.product LIMIT 100;
SELECT * FROM humanresources.employee LIMIT 100;
SELECT * FROM purchasing.vendor LIMIT 100;

-- ğŸ”¢ FASE 3: Queries de conteo (completar threshold de 15+)
-- Estas queries aseguran que superamos el threshold de 15 SELECTs
SELECT COUNT(*) FROM sales.customer;
SELECT COUNT(*) FROM sales.salesorderheader;
SELECT COUNT(*) FROM production.product;
SELECT COUNT(*) FROM person.person;
SELECT COUNT(*) FROM person.address;
SELECT COUNT(*) FROM humanresources.employee;

-- âœ… TOTAL: 20 SELECTs ejecutados en ~30 segundos
-- ğŸ¬ DEMO TIP: Explicar al cliente que esta actividad es sospechosa porque:
--    1. Demasiadas SELECTs en poco tiempo (20 en 5 min es inusual)
--    2. PatrÃ³n de reconocimiento (pg_catalog, information_schema)
--    3. ExtracciÃ³n masiva de mÃºltiples tablas sensibles
--    4. TÃ­pico de ataques de Data Exfiltration o SQL Injection

-- â¸ï¸ PAUSA PARA LA DEMO (1-2 minutos):
-- Mientras esperas la ingesta, explica al cliente:
-- - "Estos logs se estÃ¡n enviando a Event Hub en tiempo real"
-- - "Stream Analytics estÃ¡ procesando y enriqueciendo los datos"
-- - "En 1-2 minutos veremos la anomalÃ­a en el dashboard de Fabric"
-- Luego, abre el dashboard y muestra la AnomalÃ­a 1 con todos los detalles.
-- ============================================================================


-- ============================================================================
-- TEST 2: ANOMALÃA 2 - Operaciones Destructivas Masivas
-- ============================================================================
-- ğŸ“Š Requisito: >5 operaciones destructivas en ventanas de 2 minutos
--             (Query: kql-queries-PRODUCTION.kql lÃ­neas 76-122)
-- ğŸ¯ Estrategia: Crear tabla temporal y ejecutar 6 UPDATEs/DELETEs rÃ¡pidamente
-- â±ï¸ Tiempo de ejecuciÃ³n: ~1 minuto
-- ğŸ“ˆ Resultado esperado en dashboard (1-2 min despuÃ©s):
--    - AnomalyType: Mass Destructive Operations
--    - OperationCount: 6
--    - Operations: UPDATE, DELETE
--    - TablesAffected: temp_test_anomaly
--    - SampleMessages: Queries UPDATE/DELETE ejecutadas
--    - User/Database/SourceHost: Debe mostrar tu informaciÃ³n
-- ============================================================================

-- ğŸ—ï¸ PREPARACIÃ“N: Crear tabla temporal para pruebas
-- (Esta tabla solo existe durante la demo, se elimina al final)
DROP TABLE IF EXISTS temp_test_anomaly CASCADE;
CREATE TABLE temp_test_anomaly (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100),
    value INTEGER DEFAULT 0,
    created_at TIMESTAMP DEFAULT NOW()
);

-- ğŸ“¥ INSERTAR DATOS: Crear 10 registros de prueba
INSERT INTO temp_test_anomaly (name, value) VALUES 
    ('Test Record 1', 100),
    ('Test Record 2', 200),
    ('Test Record 3', 300),
    ('Test Record 4', 400),
    ('Test Record 5', 500),
    ('Test Record 6', 600),
    ('Test Record 7', 700),
    ('Test Record 8', 800),
    ('Test Record 9', 900),
    ('Test Record 10', 1000);

-- âš ï¸ FASE DESTRUCTIVA: Ejecutar 6 operaciones destructivas EN MENOS DE 2 MINUTOS
-- IMPORTANTE: Ejecuta estas 6 queries rÃ¡pidamente (copy/paste todo el bloque)
UPDATE temp_test_anomaly SET name = 'Updated Record 1', value = 9999 WHERE id = 1;
UPDATE temp_test_anomaly SET name = 'Updated Record 2', value = 9999 WHERE id = 2;
UPDATE temp_test_anomaly SET name = 'Updated Record 3', value = 9999 WHERE id = 3;
DELETE FROM temp_test_anomaly WHERE id = 4;
DELETE FROM temp_test_anomaly WHERE id = 5;
UPDATE temp_test_anomaly SET name = 'Updated Record 6', value = 9999 WHERE id = 6;

-- âœ… TOTAL: 6 operaciones destructivas ejecutadas en < 2 minutos
-- ğŸ¬ DEMO TIP: Explicar al cliente que esta actividad es sospechosa porque:
--    1. Demasiadas operaciones destructivas en poco tiempo (6 en 2 min)
--    2. PatrÃ³n tÃ­pico de:
--       - Insider threat (empleado malicioso)
--       - Ransomware modificando/eliminando datos
--       - Error humano (script ejecutado sin WHERE clause)
--       - SQL Injection atacando datos
--    3. La query detecta: UPDATE, DELETE, TRUNCATE, DROP TABLE/DATABASE
--    4. El threshold de >5 en 2 min filtra mantenimiento normal

-- â¸ï¸ PAUSA PARA LA DEMO (1-2 minutos):
-- Explicar al cliente mientras esperas:
-- - "La query agrupa operaciones destructivas en ventanas de 2 minutos"
-- - "bin(EventProcessedUtcTime, 2m) permite detectar rÃ¡fagas de actividad"
-- - "Si un usuario ejecuta 6 DELETEs/UPDATEs en 2 min, es anormal"
-- Luego, abre el dashboard y muestra la AnomalÃ­a 2 con:
-- - OperationCount = 6
-- - Operations = "UPDATE, DELETE"
-- - TablesAffected = "temp_test_anomaly"
-- - SampleMessages con las queries ejecutadas
-- ============================================================================


-- ============================================================================
-- TEST 3: ANOMALÃA 3 - Escalada de Errores CrÃ­ticos
-- ============================================================================
-- ğŸ“Š Requisito: >15 errores crÃ­ticos (ERROR/FATAL/PANIC) en 1 minuto
--             (Query: kql-queries-PRODUCTION.kql lÃ­neas 128-184)
-- ğŸ¯ Estrategia: Ejecutar 20 queries invÃ¡lidas consecutivamente
-- â±ï¸ Tiempo de ejecuciÃ³n: ~20 segundos
-- ğŸ“ˆ Resultado esperado en dashboard (1-2 min despuÃ©s):
--    - AnomalyType: Critical Error Spike
--    - ErrorCount: ~20
--    - ErrorTypes: Permission Error, Other Error
--    - ErrorCodes: 42P01 (undefined_table), 42703 (undefined_column)
--    - User/Database/SourceHost: Debe mostrar tu informaciÃ³n
-- ============================================================================

-- âš ï¸ IMPORTANTE: Estas queries generarÃ¡n errores A PROPÃ“SITO
-- Esto es normal y esperado para demostrar la detecciÃ³n de anomalÃ­as

-- ğŸš¨ FASE 1: Errores de tabla inexistente (cÃ³digo 42P01)
-- Simula un atacante intentando acceder a tablas que no existen
SELECT * FROM tabla_que_no_existe_1;
SELECT * FROM tabla_que_no_existe_2;
SELECT * FROM tabla_que_no_existe_3;
SELECT * FROM tabla_que_no_existe_4;
SELECT * FROM tabla_que_no_existe_5;
SELECT * FROM tabla_que_no_existe_6;
SELECT * FROM tabla_que_no_existe_7;
SELECT * FROM tabla_que_no_existe_8;
SELECT * FROM tabla_que_no_existe_9;
SELECT * FROM tabla_que_no_existe_10;

-- ğŸ” FASE 2: Errores de columna invÃ¡lida (cÃ³digo 42703)
-- Simula queries con sintaxis incorrecta o inyecciÃ³n SQL fallida
SELECT columna_invalida FROM sales.customer;
SELECT * FROM sales.customer WHERE columna_invalida = 'test';
SELECT id, nombre_invalido FROM person.person;
SELECT direccion_inexistente FROM person.address;
SELECT codigo_erroneo FROM production.product;

-- ğŸ”’ FASE 3: MÃ¡s errores para alcanzar threshold de 15+ en 1 minuto
-- EJECUTA ESTE BLOQUE RÃPIDAMENTE (copy/paste todo junto)
SELECT * FROM tabla_inexistente_11;
SELECT * FROM tabla_inexistente_12;
SELECT * FROM tabla_inexistente_13;
SELECT * FROM tabla_inexistente_14;
SELECT * FROM tabla_inexistente_15;
SELECT * FROM tabla_inexistente_16;
SELECT * FROM tabla_inexistente_17;
SELECT * FROM tabla_inexistente_18;

-- âœ… TOTAL: ~23 errores generados en ~20 segundos
-- ğŸ¬ DEMO TIP: Explicar al cliente que esta actividad es crÃ­tica porque:
--    1. MÃ¡s de 15 errores por minuto es extremadamente inusual
--    2. Puede indicar:
--       - ğŸ”´ Brute Force Attack (intentos de autenticaciÃ³n fallidos)
--       - ğŸ”´ SQL Injection (atacante probando queries maliciosas)
--       - ğŸŸ  AplicaciÃ³n mal configurada (connection string incorrecta)
--       - ğŸŸ  Problema de permisos (usuario sin acceso a tablas)
--    3. La query categoriza errores en tipos:
--       - Authentication Failure (brute force)
--       - Permission Denied (escalada de privilegios)
--       - Connection Error (DoS attack o fallo de red)
--       - Resource Exhausted (out of memory/disk)
--       - Other Error (syntax errors, tablas inexistentes)
--    4. El threshold de >15 por minuto es muy conservador (solo incidentes serios)

-- â¸ï¸ PAUSA PARA LA DEMO (1-2 minutos):
-- Explicar al cliente mientras esperas:
-- - "La query agrupa errores en ventanas de 1 minuto: bin(EventProcessedUtcTime, 1m)"
-- - "Extrae informaciÃ³n del usuario/database/host desde los mensajes de error"
-- - "Si no hay user en el error, correlaciona con CONNECTION logs usando processId"
-- - "Esto permite identificar QUIÃ‰N estÃ¡ generando los errores"
-- 
-- ğŸ” TROUBLESHOOTING: Si no ves resultados en el dashboard:
-- 1. Aumenta la ventana de tiempo de 5m a 30m (editado en kql-queries-PRODUCTION.kql)
-- 2. Threshold eliminado temporalmente (muestra todos los buckets de errores)
-- 3. Ordenado por ErrorCount desc para ver los picos primero
-- 4. Fallback triple aÃ±adido: DirectUser â†’ SessionUser â†’ "UNKNOWN"
--
-- Luego, abre el dashboard y muestra la AnomalÃ­a 3 con:
-- - ErrorCount: Cualquier valor (sin threshold, verÃ¡s todos los buckets)
-- - ErrorTypes = "Permission Error" (cÃ³digo 42xxx)
-- - ErrorCodes = "42P01, 42703" (undefined_table, undefined_column)
-- - SampleErrors con mensajes de las queries fallidas
-- - User/Database/SourceHost identificados (con fallback a "UNKNOWN" si es necesario)
--
-- âš™ï¸ PARA PRODUCCIÃ“N: DespuÃ©s de verificar que funciona:
-- - Restaura ventana a ago(5m)
-- - Agrega de nuevo: | where ErrorCount > 15
-- - Esto filtrarÃ¡ solo anomalÃ­as crÃ­ticas (>15 errores/minuto)
-- ============================================================================


-- ============================================================================
-- TEST AUTH (OPCIONAL): TILE - Fallos de AutenticaciÃ³n (Brute Force)
-- ============================================================================
-- ğŸ“Š Requisito: Detectar intentos de brute force (>3 fallos por usuario/host)
--             (Query: kql-queries-PRODUCTION.kql lÃ­neas 700-730 - TILE 12)
-- ğŸ¯ Estrategia: Intentar conectarse con contraseÃ±a incorrecta 10-20 veces
-- â±ï¸ Tiempo de ejecuciÃ³n: ~1-2 minutos
-- 
-- âš ï¸ NOTA: Este NO es una AnomalÃ­a principal (1-7), es un TILE del dashboard
--          Pero es Ãºtil para demostrar detecciÃ³n de brute force attacks
--
-- ğŸ“ˆ Resultado esperado en dashboard:
--    - TILE "Fallos de AutenticaciÃ³n"
--    - User: tu_usuario_test
--    - SourceHost: tu_ip
--    - FailedAttempts: 10-20
--    - ThreatLevel: ğŸŸ  HIGH (si >5 fallos) o ğŸ”´ CRITICAL (si >10 fallos)
-- ============================================================================

-- âš ï¸ IMPORTANTE: Este test NO se puede ejecutar desde una conexiÃ³n autenticada
-- Debes ejecutarlo FUERA de esta sesiÃ³n SQL, usando terminal o script

-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
-- OPCIÃ“N 1: Script Bash (Linux/Mac/Windows Git Bash) - RECOMENDADO PARA DEMO
-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
-- Guarda este script como: test_brute_force.sh
-- EjecÃºtalo: bash test_brute_force.sh

#!/bin/bash
# CAMBIA ESTOS VALORES POR TUS DATOS REALES:
SERVER="advpsqlfxuk.postgres.database.azure.com"  # Tu servidor PostgreSQL
USER="testuser"                                    # Usuario de prueba
DATABASE="adventureworks"                          # Base de datos
WRONG_PASSWORD="INTENTIONALLY_WRONG_PASSWORD_123"  # Password incorrecta a propÃ³sito

echo "ğŸš¨ Iniciando test de brute force attack..."
echo "Servidor: $SERVER"
echo "Usuario: $USER"
echo "Generando 20 intentos fallidos en 60 segundos..."
echo ""

for i in {1..20}; do
  echo -n "Intento $i/20... "
  # PGPASSWORD fuerza la password sin prompt interactivo
  # 2>&1 redirige errores para capturar el mensaje
  # grep -q busca el error de autenticaciÃ³n
  PGPASSWORD="$WRONG_PASSWORD" psql -h "$SERVER" -U "$USER" -d "$DATABASE" -c "SELECT 1;" 2>&1 | grep -q "password authentication failed"
  
  if [ $? -eq 0 ]; then
    echo "âŒ FAILED (autenticaciÃ³n fallida detectada)"
  else
    echo "âš ï¸ Error inesperado (verificar conectividad)"
  fi
  
  # Esperar 3 segundos entre intentos para simular ataque realista
  sleep 3
done

echo ""
echo "âœ… Test completado: 20 intentos fallidos generados"
echo "â±ï¸ Espera 1-2 minutos y verifica el dashboard en Fabric"
echo "ğŸ“Š Busca en TILE 'Fallos de AutenticaciÃ³n':"
echo "   - User: $USER"
echo "   - FailedAttempts: ~20"
echo "   - ThreatLevel: ğŸ”´ CRITICAL"


-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
-- OPCIÃ“N 2: Script PowerShell (Windows) - ALTERNATIVA PARA DEMO EN WINDOWS
-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
-- Guarda este script como: test_brute_force.ps1
-- EjecÃºtalo: powershell -File test_brute_force.ps1

<#
# CAMBIA ESTOS VALORES POR TUS DATOS REALES:
$SERVER = "advpsqlfxuk.postgres.database.azure.com"
$USER = "testuser"
$DATABASE = "adventureworks"
$WRONG_PASSWORD = "INTENTIONALLY_WRONG_PASSWORD_123"

Write-Host "ğŸš¨ Iniciando test de brute force attack..." -ForegroundColor Red
Write-Host "Servidor: $SERVER"
Write-Host "Usuario: $USER"
Write-Host "Generando 20 intentos fallidos en 60 segundos..."
Write-Host ""

1..20 | ForEach-Object {
    Write-Host -NoNewline "Intento $_/20... "
    
    # Configurar variable de entorno para password (evita prompt)
    $env:PGPASSWORD = $WRONG_PASSWORD
    
    # Intentar conexiÃ³n (redirigir errores a $null para evitar spam en consola)
    $result = psql -h $SERVER -U $USER -d $DATABASE -c "SELECT 1;" 2>&1
    
    if ($result -match "password authentication failed") {
        Write-Host "âŒ FAILED (autenticaciÃ³n fallida detectada)" -ForegroundColor Red
    } else {
        Write-Host "âš ï¸ Error inesperado (verificar psql instalado)" -ForegroundColor Yellow
    }
    
    # Esperar 3 segundos entre intentos
    Start-Sleep -Seconds 3
}

Write-Host ""
Write-Host "âœ… Test completado: 20 intentos fallidos generados" -ForegroundColor Green
Write-Host "â±ï¸ Espera 1-2 minutos y verifica el dashboard en Fabric"
Write-Host "ğŸ“Š Busca en TILE 'Fallos de AutenticaciÃ³n':"
Write-Host "   - User: $USER"
Write-Host "   - FailedAttempts: ~20"
Write-Host "   - ThreatLevel: ğŸ”´ CRITICAL"
#>


-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
-- OPCIÃ“N 3: Script Python (Multiplataforma) - SI NO TIENES PSQL INSTALADO
-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
-- Guarda este script como: test_brute_force.py
-- Ejecuta: python test_brute_force.py
-- Prerequisito: pip install psycopg2-binary

<#
import psycopg2
import time

# CAMBIA ESTOS VALORES POR TUS DATOS REALES:
SERVER = "advpsqlfxuk.postgres.database.azure.com"
USER = "testuser"
DATABASE = "adventureworks"
WRONG_PASSWORD = "INTENTIONALLY_WRONG_PASSWORD_123"

print("ğŸš¨ Iniciando test de brute force attack...")
print(f"Servidor: {SERVER}")
print(f"Usuario: {USER}")
print("Generando 20 intentos fallidos en 60 segundos...\n")

for i in range(1, 21):
    print(f"Intento {i}/20... ", end="", flush=True)
    
    try:
        # Intentar conectar con password incorrecta
        conn = psycopg2.connect(
            host=SERVER,
            database=DATABASE,
            user=USER,
            password=WRONG_PASSWORD,
            connect_timeout=5
        )
        conn.close()
        print("âš ï¸ UNEXPECTED: ConexiÃ³n exitosa (verificar password)")
    
    except psycopg2.OperationalError as e:
        if "password authentication failed" in str(e):
            print("âŒ FAILED (autenticaciÃ³n fallida detectada)")
        else:
            print(f"âš ï¸ Error: {e}")
    
    # Esperar 3 segundos entre intentos
    time.sleep(3)

print("\nâœ… Test completado: 20 intentos fallidos generados")
print("â±ï¸ Espera 1-2 minutos y verifica el dashboard en Fabric")
print("ğŸ“Š Busca en TILE 'Fallos de AutenticaciÃ³n':")
print(f"   - User: {USER}")
print("   - FailedAttempts: ~20")
print("   - ThreatLevel: ğŸ”´ CRITICAL")
#>


-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
-- OPCIÃ“N 4: Azure Portal (SIN CÃ“DIGO) - MÃS RÃPIDO PARA DEMO CON CLIENTE
-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
-- Si no tienes psql instalado o prefieres evitar scripts:
--
-- 1. Ve a Azure Portal â†’ Tu PostgreSQL Flexible Server
-- 2. Networking â†’ Deshabilita "Public access" temporalmente
-- 3. Desde Azure Data Studio o cualquier cliente, intenta conectarte 20 veces
--    (fallarÃ¡ porque el servidor rechaza conexiones)
-- 4. Restaura "Public access" despuÃ©s del test
--
-- VENTAJA: No requiere instalar nada, muy rÃ¡pido para demos
-- DESVENTAJA: Genera CONNECTION ERRORS en vez de AUTHENTICATION ERRORS
--             (pero igual dispara la AnomalÃ­a 3 - Error Spike)


-- ğŸ¬ DEMO TIP: Explicar al cliente durante la ejecuciÃ³n
-- Mientras el script ejecuta (toma ~60 segundos), explica:
-- - "Este script simula un ataque de brute force"
-- - "EstÃ¡ intentando conectarse con password incorrecta 20 veces"
-- - "Cada intento genera un error de autenticaciÃ³n en PostgreSQL"
-- - "Los logs se envÃ­an a Fabric en tiempo real"
-- - "La query detecta >3 fallos del mismo usuario/IP = ThreatLevel HIGH"
-- - "Si son >10 fallos = ThreatLevel CRITICAL (posible ataque)"
--
-- Resultado esperado en dashboard (1-2 min despuÃ©s):
-- - TILE "Fallos de AutenticaciÃ³n":
--   * User: testuser
--   * ClientHost: tu_ip_publica (ej: 203.0.113.45)
--   * FailedAttempts: 20
--   * ThreatLevel: ğŸ”´ CRITICAL
--   * Databases: adventureworks
--   * FirstAttempt / LastAttempt: timestamps del ataque
--
-- - (BONUS) Puede disparar tambiÃ©n ANOMALÃA 3 (Error Spike) si >15 fallos/min
-- ============================================================================


-- ============================================================================
-- ============================================================================
--                    ğŸ”´ ANOMALÃAS AVANZADAS (Tests 4-7)
--              Patrones que Defender/SIEM NO pueden detectar
-- ============================================================================
-- ============================================================================
-- Estos tests simulan patrones de ataque sofisticados que requieren:
-- âœ… AnÃ¡lisis de baseline comportamental (ML)
-- âœ… CorrelaciÃ³n cross-signal (usuario + tiempo + tipo de query)
-- âœ… ComparaciÃ³n con patrones histÃ³ricos (imposible para SIEM basado en reglas)
--
-- Defender/SIEM verÃ­a estos como eventos "normales" individuales porque:
-- âŒ No conocen tus horarios de trabajo
-- âŒ No pueden establecer baselines por usuario
-- âŒ No tienen contexto sobre patrones normales de privilegios
-- âŒ Procesan eventos de forma aislada, no como secuencias de comportamiento
-- ============================================================================


-- ============================================================================
-- TEST 4: ANOMALÃA 4 - Escalada de Privilegios (Privilege Escalation)
-- ============================================================================
-- ğŸ“Š Requisito: Detectar >3 operaciones de privilegios en 5 minutos
--             (Query: kql-queries-PRODUCTION.kql lÃ­neas 252-314)
-- ğŸ¯ Estrategia: Ejecutar secuencia de GRANTs sospechosa
-- â±ï¸ Tiempo de ejecuciÃ³n: ~30 segundos
-- 
-- âš ï¸ POR QUÃ‰ DEFENDER NO LO DETECTA:
--    - Defender ve "GRANT SELECT TO user" = operaciÃ³n de admin normal âœ…
--    - NO detecta la VELOCIDAD (5 GRANTs en 2 minutos = sospechoso)
--    - NO detecta el PATRÃ“N (mismo usuario otorgando permisos a sÃ­ mismo)
--    - NO correlaciona con el rol del usuario (Â¿es realmente admin?)
--
-- ğŸ“ˆ Resultado esperado en dashboard (1-2 min despuÃ©s):
--    - AnomalyType: Privilege Escalation
--    - Severity: MEDIUM/HIGH
--    - PrivilegeOpsCount: 6+
--    - Operations: GRANT, REVOKE, CREATE ROLE
--    - User: Tu usuario
-- ============================================================================

-- ğŸ—ï¸ PREPARACIÃ“N: Crear roles temporales para pruebas
DROP ROLE IF EXISTS test_analyst_v3;
DROP ROLE IF EXISTS test_developer_v3;  
DROP ROLE IF EXISTS test_admin_v3;

CREATE ROLE test_analyst_v3;
CREATE ROLE test_developer_v3;
CREATE ROLE test_admin_v3;

-- âš ï¸ FASE SOSPECHOSA: Ejecutar 6 operaciones de privilegios EN MENOS DE 5 MINUTOS
GRANT SELECT ON ALL TABLES IN SCHEMA sales TO test_analyst_v3;
GRANT INSERT, UPDATE ON ALL TABLES IN SCHEMA sales TO test_developer_v3;
GRANT ALL PRIVILEGES ON ALL TABLES IN SCHEMA sales TO test_admin_v3;
GRANT test_analyst_v3 TO test_developer_v3;  -- Escalada: developer hereda analyst
GRANT test_developer_v3 TO test_admin_v3;    -- Escalada: admin hereda developer
REVOKE ALL ON SCHEMA public FROM test_analyst_v3;  -- RevocaciÃ³n sospechosa

-- âœ… TOTAL: 6 operaciones de privilegios en rÃ¡faga
-- ğŸ¬ DEMO TIP: Cada GRANT individual es normal, pero 6 en 2 min = ataque

-- ğŸ§¹ LIMPIEZA: Eliminar roles de prueba
DROP ROLE IF EXISTS test_analyst_v3;
DROP ROLE IF EXISTS test_developer_v3;
DROP ROLE IF EXISTS test_admin_v3;


-- ============================================================================
-- TEST 5: ANOMALÃA 5 - Reconocimiento Cross-Schema (Lateral Movement)
-- ============================================================================
-- ğŸ“Š Requisito: Detectar mismo usuario accediendo >4 schemas en 10 minutos
--             (Query: kql-queries-PRODUCTION.kql lÃ­neas 316-374)
-- ğŸ¯ Estrategia: Ejecutar queries que acceden a mÃºltiples schemas
-- â±ï¸ Tiempo de ejecuciÃ³n: ~30 segundos
-- 
-- âš ï¸ POR QUÃ‰ DEFENDER NO LO DETECTA:
--    - Defender ve "SELECT from sales.X" = query normal âœ…
--    - NO correlaciona que el mismo usuario accediÃ³ 5 schemas diferentes
--    - NO tiene contexto de que este usuario normalmente usa 1 schema
--    - Movimiento lateral es invisible sin anÃ¡lisis cross-schema
--
-- ğŸ“ˆ Resultado esperado en dashboard (1-2 min despuÃ©s):
--    - AnomalyType: Cross-Schema Reconnaissance
--    - Severity: MEDIUM/HIGH
--    - SchemasAccessed: 5+
--    - SchemaList: sales, production, person, humanresources, purchasing
--    - User: Tu usuario
-- ============================================================================

-- ğŸ” Queries que acceden a mÃºltiples schemas en rÃ¡faga
SELECT datname, encoding FROM pg_database WHERE datistemplate = false;
SELECT nspname FROM pg_namespace WHERE nspname NOT LIKE 'pg_%';

-- Acceso a diferentes schemas de negocio
SELECT * FROM sales.customer LIMIT 1;
SELECT * FROM production.product LIMIT 1;
SELECT * FROM person.person LIMIT 1;
SELECT * FROM humanresources.employee LIMIT 1;
SELECT * FROM purchasing.vendor LIMIT 1;

-- Queries de reconocimiento de estructura multi-schema
SELECT table_schema, COUNT(*) as table_count 
FROM information_schema.tables 
WHERE table_schema NOT IN ('pg_catalog', 'information_schema')
GROUP BY table_schema;

-- âœ… TOTAL: 8 queries de reconocimiento cross-schema
-- ğŸ¬ DEMO TIP: Usuario normal = 1-2 schemas. 5+ schemas = mapeo de atacante
-- ============================================================================


-- ============================================================================
-- TEST 6: ANOMALÃA 6 - EnumeraciÃ³n Profunda de Schema (Deep Scan)
-- ============================================================================
-- ğŸ“Š Requisito: Detectar >10 queries a tablas de sistema en 5 minutos
--             (Query: kql-queries-PRODUCTION.kql lÃ­neas 377-455)
-- ğŸ¯ Estrategia: Ejecutar reconocimiento exhaustivo del schema
-- â±ï¸ Tiempo de ejecuciÃ³n: ~30 segundos
-- 
-- âš ï¸ POR QUÃ‰ DEFENDER NO LO DETECTA:
--    - Defender ve "SELECT from pg_tables" = query de metadata âœ…
--    - NO detecta la PROFUNDIDAD (atacante mapeando TODA la estructura)
--    - NO detecta la SECUENCIA (pg_tables â†’ pg_columns â†’ pg_proc)
--    - Este patrÃ³n es preparaciÃ³n para SQL injection o exfiltraciÃ³n
--
-- ğŸ“ˆ Resultado esperado en dashboard (1-2 min despuÃ©s):
--    - AnomalyType: Deep Schema Enumeration
--    - Severity: MEDIUM/HIGH/CRITICAL
--    - SystemTableQueries: 15+
--    - TablesScanned: pg_tables, pg_class, pg_attribute, pg_proc...
--    - RiskLevel: ğŸ”´ HIGH - Multi-table scan
--    - User: Tu usuario
-- ============================================================================

-- ğŸ” FASE 1: Mapeo de estructura de tablas
SELECT schemaname, tablename, tableowner FROM pg_tables 
    WHERE schemaname NOT LIKE 'pg_%' LIMIT 5;
SELECT table_schema, table_name, table_type FROM information_schema.tables 
    WHERE table_schema NOT LIKE 'pg_%' LIMIT 5;
SELECT relname, relkind FROM pg_class WHERE relkind = 'r' LIMIT 5;

-- ğŸ” FASE 2: Mapeo de columnas (para saber quÃ© datos robar)
SELECT column_name, data_type, is_nullable FROM information_schema.columns 
    WHERE table_schema = 'sales' LIMIT 10;
SELECT attname, atttypid FROM pg_attribute 
    WHERE attrelid = 'sales.customer'::regclass AND attnum > 0 LIMIT 5;

-- ğŸ” FASE 3: Mapeo de funciones y procedimientos
SELECT proname, pronargs FROM pg_proc WHERE pronamespace != 11 LIMIT 5;
SELECT routine_name, routine_type FROM information_schema.routines 
    WHERE routine_schema NOT IN ('pg_catalog', 'information_schema') LIMIT 5;

-- ğŸ” FASE 4: Mapeo de constraints y relaciones
SELECT conname, contype FROM pg_constraint LIMIT 5;
SELECT constraint_name, table_name, constraint_type FROM information_schema.table_constraints 
    WHERE table_schema = 'sales' LIMIT 5;
SELECT indexname FROM pg_indexes WHERE schemaname = 'sales' LIMIT 5;

-- ğŸ” FASE 5: InformaciÃ³n de usuarios y permisos
SELECT rolname, rolsuper FROM pg_roles LIMIT 5;
SELECT grantee, privilege_type, table_name FROM information_schema.table_privileges 
    WHERE table_schema = 'sales' LIMIT 5;

-- âœ… TOTAL: 15+ queries a tablas de sistema en secuencia
-- ğŸ¬ DEMO TIP: 
--    - "Cada query parece inocente"
--    - "La SECUENCIA revela intenciÃ³n: mapear toda la BD"
--    - "Defender ve 15 queries normales, Fabric ve 1 ataque coordinado"
-- ============================================================================


-- ============================================================================
-- TEST 7: ANOMALÃA 7 - DesviaciÃ³n de Baseline ML (ML Baseline Deviation)
-- ============================================================================
-- ğŸ“Š Requisito: Generar actividad que desvÃ­e del baseline ML
--             (Query: series_decompose_anomalies en postgres_activity_metrics)
-- ğŸ¯ Estrategia: Ejecutar MUCHAS queries para crear spike de actividad
-- 
-- âš ï¸ IMPORTANTE: Este test requiere:
--    1. Tabla postgres_activity_metrics creada (ANOMALY-DETECTION-SETUP.kql)
--    2. Al menos 7 dÃ­as de datos histÃ³ricos para baseline
--    3. Ejecutar en horario INUSUAL para tu patrÃ³n (ej: 3 AM)
--
-- âš ï¸ POR QUÃ‰ DEFENDER NO LO DETECTA:
--    - Defender ve "usuario X ejecutÃ³ SELECT" = evento normal âœ…
--    - NO sabe que este usuario NUNCA trabaja a las 3 AM
--    - NO tiene baseline del patrÃ³n horario de cada usuario
--    - Solo Fabric ML con series_decompose_anomalies puede detectarlo
--
-- ğŸ“ˆ Resultado esperado en dashboard (5-10 min despuÃ©s):
--    - AnomalyType: ML Baseline Deviation
--    - AnomalyDirection: ğŸ“ˆ Above Normal
--    - DeviationScore: >1.5 (debe ser >2.0 para HIGH, >3.0 para CRITICAL)
--    - ServerName: Tu servidor
-- ============================================================================

-- ğŸ• FASE 1: Generar SPIKE de actividad (50+ queries en 5 minutos)
-- El objetivo es generar actividad MUY POR ENCIMA del baseline normal

SELECT current_timestamp as access_time, 'ML SPIKE TEST - START' as test_type;

-- ğŸ”¥ RÃFAGA 1: Accesos masivos a tablas de negocio (20 queries)
SELECT * FROM sales.customer LIMIT 1;
SELECT * FROM sales.salesorderheader LIMIT 1;
SELECT * FROM sales.salesorderdetail LIMIT 1;
SELECT * FROM sales.store LIMIT 1;
SELECT * FROM sales.salesperson LIMIT 1;
SELECT * FROM person.person LIMIT 1;
SELECT * FROM person.address LIMIT 1;
SELECT * FROM person.emailaddress LIMIT 1;
SELECT * FROM person.phonenumbertype LIMIT 1;
SELECT * FROM person.businessentity LIMIT 1;
SELECT * FROM production.product LIMIT 1;
SELECT * FROM production.productcategory LIMIT 1;
SELECT * FROM production.productsubcategory LIMIT 1;
SELECT * FROM production.productmodel LIMIT 1;
SELECT * FROM production.productinventory LIMIT 1;
SELECT * FROM humanresources.employee LIMIT 1;
SELECT * FROM humanresources.department LIMIT 1;
SELECT * FROM humanresources.shift LIMIT 1;
SELECT * FROM purchasing.vendor LIMIT 1;
SELECT * FROM purchasing.purchaseorderheader LIMIT 1;

-- ğŸ”¥ RÃFAGA 2: Queries de conteo (10 queries mÃ¡s)
SELECT COUNT(*) FROM sales.customer;
SELECT COUNT(*) FROM sales.salesorderheader;
SELECT COUNT(*) FROM person.person;
SELECT COUNT(*) FROM production.product;
SELECT COUNT(*) FROM humanresources.employee;
SELECT COUNT(*) FROM purchasing.vendor;
SELECT COUNT(*) FROM sales.salesorderdetail;
SELECT COUNT(*) FROM person.address;
SELECT COUNT(*) FROM production.productinventory;
SELECT COUNT(*) FROM humanresources.department;

-- ğŸ”¥ RÃFAGA 3: Queries con agregaciones (10 queries mÃ¡s)
SELECT MAX(totaldue) FROM sales.salesorderheader;
SELECT MIN(totaldue) FROM sales.salesorderheader;
SELECT AVG(listprice) FROM production.product;
SELECT SUM(orderqty) FROM sales.salesorderdetail;
SELECT COUNT(DISTINCT customerid) FROM sales.customer;
SELECT MAX(modifieddate) FROM person.person;
SELECT MIN(hiredate) FROM humanresources.employee;
SELECT AVG(standardcost) FROM production.product;
SELECT SUM(quantity) FROM production.productinventory;
SELECT COUNT(DISTINCT departmentid) FROM humanresources.department;

-- ğŸ”¥ RÃFAGA 4: Queries con JOINs (10 queries mÃ¡s - mÃ¡s carga)
SELECT c.customerid, p.firstname FROM sales.customer c 
    JOIN person.person p ON c.personid = p.businessentityid LIMIT 5;
SELECT o.salesorderid, c.customerid FROM sales.salesorderheader o 
    JOIN sales.customer c ON o.customerid = c.customerid LIMIT 5;
SELECT e.businessentityid, d.name FROM humanresources.employee e 
    JOIN humanresources.employeedepartmenthistory edh ON e.businessentityid = edh.businessentityid
    JOIN humanresources.department d ON edh.departmentid = d.departmentid LIMIT 5;
SELECT p.productid, pc.name FROM production.product p 
    JOIN production.productsubcategory ps ON p.productsubcategoryid = ps.productsubcategoryid
    JOIN production.productcategory pc ON ps.productcategoryid = pc.productcategoryid LIMIT 5;
SELECT v.businessentityid, pod.productid FROM purchasing.vendor v 
    JOIN purchasing.purchaseorderheader poh ON v.businessentityid = poh.vendorid
    JOIN purchasing.purchaseorderdetail pod ON poh.purchaseorderid = pod.purchaseorderid LIMIT 5;
SELECT a.addressid, sp.name FROM person.address a 
    JOIN person.stateprovince sp ON a.stateprovinceid = sp.stateprovinceid LIMIT 5;
SELECT p.businessentityid, e.emailaddressid FROM person.person p 
    JOIN person.emailaddress e ON p.businessentityid = e.businessentityid LIMIT 5;
SELECT soh.salesorderid, sod.productid, p.name FROM sales.salesorderheader soh
    JOIN sales.salesorderdetail sod ON soh.salesorderid = sod.salesorderid
    JOIN production.product p ON sod.productid = p.productid LIMIT 5;
SELECT c.customerid, a.city FROM sales.customer c 
    JOIN person.businessentityaddress bea ON c.personid = bea.businessentityid
    JOIN person.address a ON bea.addressid = a.addressid LIMIT 5;
SELECT e.businessentityid, p.firstname, p.lastname FROM humanresources.employee e
    JOIN person.person p ON e.businessentityid = p.businessentityid LIMIT 5;

SELECT current_timestamp as access_time, 'ML SPIKE TEST - END' as test_type;

-- âœ… TOTAL: 52 queries ejecutadas en rÃ¡faga (~1-2 minutos)
-- ğŸ¬ DEMO TIP: 
--    - "Ejecutamos 52 queries en 2 minutos"
--    - "El baseline normal es ~5-10 queries por ventana de 5 minutos"
--    - "ML detecta que esto es 5-10x el baseline = ANOMALÃA"
--    - "DeviationScore > 2.0 = HIGH, > 3.0 = CRITICAL"
--
-- â¸ï¸ PAUSA PARA LA DEMO (5-10 minutos):
-- El ML necesita mÃ¡s tiempo para procesar y comparar con el baseline.
-- Mientras esperas, ejecuta los otros tests o explica:
-- - "series_decompose_anomalies() compara con los Ãºltimos 7 dÃ­as"
-- - "Detecta seasonality (patrones horarios/diarios) automÃ¡ticamente"
-- - "Si la actividad actual estÃ¡ 1.5Ïƒ por encima del baseline = anomalÃ­a"
-- ============================================================================


-- ============================================================================
-- LIMPIEZA POST-DEMO
-- ============================================================================
-- âš ï¸ EJECUTAR DESPUÃ‰S DE LA DEMO PARA ELIMINAR TABLA TEMPORAL
-- ============================================================================

-- Eliminar tabla de prueba creada en TEST 2
DROP TABLE IF EXISTS temp_test_anomaly CASCADE;

-- Verificar que se eliminÃ³ correctamente
SELECT 
    CASE 
        WHEN NOT EXISTS (SELECT 1 FROM information_schema.tables WHERE table_name = 'temp_test_anomaly')
        THEN 'âœ… Tabla temp_test_anomaly eliminada correctamente'
        ELSE 'âš ï¸ La tabla aÃºn existe'
    END AS cleanup_status;

-- ğŸ¬ DEMO TIP: Ejecuta esto al final de la demo para dejar la base de datos limpia
-- ============================================================================

-- ============================================================================
-- VERIFICACIÃ“N DE RESULTADOS - CHECKLIST PARA LA DEMO
-- ============================================================================
-- â±ï¸ ESPERA 1-2 MINUTOS DESPUÃ‰S DE CADA TEST PARA VER RESULTADOS
-- ============================================================================

-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
-- 1. VERIFICACIÃ“N EN DASHBOARD DE FABRIC
-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

-- ğŸ“Š TILE "AnomalÃ­as Detectadas" (Panel Principal):
-- â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
-- â”‚ âœ… TEST 1 - AnomalÃ­a "Potential Data Exfiltration"                    â”‚
-- â”‚    - SelectCount: ~20                                                   â”‚
-- â”‚    - TablesAccessed: pg_tables, pg_class, customer, salesorderheader... â”‚
-- â”‚    - SampleQueries: 3 primeras queries ejecutadas                       â”‚
-- â”‚    - User/Database/SourceHost: TU informaciÃ³n (NO "UNKNOWN")            â”‚
-- â”‚                                                                         â”‚
-- â”‚ âœ… TEST 2 - AnomalÃ­a "Mass Destructive Operations"                     â”‚
-- â”‚    - OperationCount: 6                                                  â”‚
-- â”‚    - Operations: UPDATE, DELETE                                         â”‚
-- â”‚    - TablesAffected: temp_test_anomaly                                  â”‚
-- â”‚    - SampleMessages: Queries UPDATE/DELETE ejecutadas                   â”‚
-- â”‚    - User/Database/SourceHost: TU informaciÃ³n                           â”‚
-- â”‚                                                                         â”‚
-- â”‚ âœ… TEST 3 - AnomalÃ­a "Critical Error Spike"                            â”‚
-- â”‚    - ErrorCount: ~20-23                                                 â”‚
-- â”‚    - ErrorTypes: Other Error (o Permission Error)                       â”‚
-- â”‚    - ErrorCodes: 42P01 (undefined_table), 42703 (undefined_column)      â”‚
-- â”‚    - SampleErrors: Mensajes de queries fallidas                         â”‚
-- â”‚    - User/Database/SourceHost: TU informaciÃ³n                           â”‚
-- â”‚                                                                         â”‚
-- â”‚ âœ… TEST 4 - AnomalÃ­a "Privilege Escalation" ğŸ”´ AVANZADA                â”‚
-- â”‚    - AnomalyType: Privilege Escalation                                  â”‚
-- â”‚    - PrivilegeOpsCount: 6+                                              â”‚
-- â”‚    - Operations: CREATE ROLE, GRANT, REVOKE                             â”‚
-- â”‚    - User/Database/SourceHost: TU informaciÃ³n                           â”‚
-- â”‚                                                                         â”‚
-- â”‚ âœ… TEST 5 - AnomalÃ­a "Cross-Schema Reconnaissance" ğŸ”´ AVANZADA         â”‚
-- â”‚    - AnomalyType: Cross-Schema Reconnaissance                           â”‚
-- â”‚    - SchemasAccessed: 5+ (sales, production, person, hr, purchasing)    â”‚
-- â”‚    - User/Database/SourceHost: TU informaciÃ³n                           â”‚
-- â”‚                                                                         â”‚
-- â”‚ âœ… TEST 6 - AnomalÃ­a "Deep Schema Enumeration" ğŸ”´ AVANZADA             â”‚
-- â”‚    - AnomalyType: Deep Schema Enumeration                               â”‚
-- â”‚    - SystemTableQueries: 15+                                            â”‚
-- â”‚    - TablesScanned: pg_tables, pg_class, pg_attribute, pg_proc...       â”‚
-- â”‚    - User/Database/SourceHost: TU informaciÃ³n                           â”‚
-- â”‚                                                                         â”‚
-- â”‚ âœ… TEST 7 - AnomalÃ­a "ML Baseline Deviation" ğŸ”´ AVANZADA               â”‚
-- â”‚    - AnomalyType: ML Baseline Deviation                                 â”‚
-- â”‚    - DeviationScore: >1.5 (>2.0 = HIGH, >3.0 = CRITICAL)               â”‚
-- â”‚    - AnomalyDirection: ğŸ“ˆ Above Normal                                  â”‚
-- â”‚    - âš ï¸ Requiere: 7 dÃ­as de datos histÃ³ricos + ejecutar a hora inusual â”‚
-- â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

-- ğŸ“Š OTROS TILES DEL DASHBOARD (VerificaciÃ³n Adicional):
-- â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
-- â”‚ âœ… TILE "TOP Usuarios por Actividad"                                   â”‚
-- â”‚    - Debe mostrar TU usuario con alta actividad                         â”‚
-- â”‚    - TotalActivity: ~40+ (20 SELECTs + 6 UPDATEs/DELETEs + 20 errores) â”‚
-- â”‚    - AuditLogs: ~26, Errors: ~20                                        â”‚
-- â”‚                                                                         â”‚
-- â”‚ âœ… TILE "TOP Hosts/IPs por Conexiones"                                 â”‚
-- â”‚    - Debe mostrar TU IP pÃºblica                                         â”‚
-- â”‚    - TotalConnections: 1+                                               â”‚
-- â”‚    - Errors: ~20 (si ejecutaste TEST 3)                                 â”‚
-- â”‚    - ErrorRate: calculado (Errors / TotalConnections)                   â”‚
-- â”‚                                                                         â”‚
-- â”‚ âœ… TILE "Fallos de AutenticaciÃ³n" (Solo si ejecutaste TEST AUTH)       â”‚
-- â”‚    - User: testuser (o el usuario que usaste)                           â”‚
-- â”‚    - ClientHost: tu_ip_publica                                          â”‚
-- â”‚    - FailedAttempts: ~20                                                â”‚
-- â”‚    - ThreatLevel: ğŸ”´ CRITICAL                                           â”‚
-- â”‚    - Databases: adventureworks                                          â”‚
-- â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
-- 2. VERIFICACIÃ“N DE QUERIES DE DIAGNÃ“STICO (OPCIONAL - TROUBLESHOOTING)
-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

-- ğŸ” Verificar que pgaudit estÃ¡ funcionando (DEBE retornar rows):
SELECT * FROM bronze_pssql_alllogs_nometrics 
WHERE EventProcessedUtcTime >= ago(5m)
  AND message contains "AUDIT:"
  AND category == "PostgreSQLLogs"
| take 10;

-- ğŸ” Verificar que User/Database/Host se estÃ¡n capturando (NO debe ser "UNKNOWN"):
SELECT 
    User = extract(@"user=([^\s,]+)", 1, message),
    Database = extract(@"database=([^\s,]+)", 1, message),
    ClientHost = extract(@"host=([^\s]+)", 1, message),
    message
FROM bronze_pssql_alllogs_nometrics
WHERE EventProcessedUtcTime >= ago(5m)
  AND (message contains "connection authorized" or message contains "connection received")
| where isnotempty(User)
| take 10;

-- ğŸ” Verificar que las anomalÃ­as se generaron (DEBE retornar 3 rows):
union
    (bronze_pssql_alllogs_nometrics | where AnomalyType == "Potential Data Exfiltration" | take 1),
    (bronze_pssql_alllogs_nometrics | where AnomalyType == "Mass Destructive Operations" | take 1),
    (bronze_pssql_alllogs_nometrics | where AnomalyType == "Critical Error Spike" | take 1)
| project AnomalyType, TimeGenerated, SelectCount, OperationCount, ErrorCount;


-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
-- 3. VERIFICACIÃ“N DE ALERTAS EN DATA ACTIVATOR (SI CONFIGURADAS)
-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

-- Si configuraste alertas en Data Activator (Reflex), verifica:
-- â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
-- â”‚ âœ… Alerta 1 - "Alert_DataExfiltration"                                  â”‚
-- â”‚    - Estado: Triggered (disparada)                                      â”‚
-- â”‚    - Trigger: SelectCount > 15                                          â”‚
-- â”‚    - Acciones: Email/Teams enviado (verificar inbox/canal)              â”‚
-- â”‚                                                                         â”‚
-- â”‚ âœ… Alerta 2 - "Alert_MassDestructiveOps"                                â”‚
-- â”‚    - Estado: Triggered                                                  â”‚
-- â”‚    - Trigger: OperationCount > 5                                        â”‚
-- â”‚    - Acciones: Email/Teams enviado                                      â”‚
-- â”‚                                                                         â”‚
-- â”‚ âœ… Alerta 3 - "Alert_ErrorSpike"                                        â”‚
-- â”‚    - Estado: Triggered                                                  â”‚
-- â”‚    - Trigger: ErrorCount > 15                                           â”‚
-- â”‚    - Acciones: Email/Teams enviado + Posible ticket en ServiceNow       â”‚
-- â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
-- 4. TROUBLESHOOTING - SI LAS ANOMALÃAS NO APARECEN
-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

-- ğŸš¨ PROBLEMA: User/Database/Host = "UNKNOWN" en las anomalÃ­as
-- ğŸ”§ SOLUCIÃ“N: Verificar extensiÃ³n pgaudit instalada

-- En PostgreSQL (ejecutar desde psql/Azure Data Studio):
SELECT * FROM pg_extension WHERE extname = 'pgaudit';
-- Si NO retorna nada, ejecuta: CREATE EXTENSION pgaudit;

-- Verificar configuraciÃ³n pgaudit:
SHOW pgaudit.log;
-- Debe retornar: 'ALL' o al menos 'READ, WRITE, DDL'
-- Si estÃ¡ vacÃ­o, configurar en Azure Portal:
-- Ir a Server Parameters â†’ pgaudit.log â†’ Valor: 'ALL' â†’ Save


-- ğŸš¨ PROBLEMA: Las anomalÃ­as no aparecen en el dashboard
-- ğŸ”§ SOLUCIÃ“N: Verificar pipeline de ingesta

-- 1. Verificar Diagnostic Settings habilitado:
--    Azure Portal â†’ PostgreSQL Flexible Server â†’ Diagnostic Settings
--    â†’ Asegurar que "PostgreSQLLogs" estÃ¡ checked y enviando a Event Hub

-- 2. Verificar Event Stream funcionando:
--    Fabric â†’ Workspace â†’ Event Streams â†’ Ver si hay datos fluyendo

-- 3. Verificar tabla recibiendo datos:
--    Ejecutar en KQL Database:
bronze_pssql_alllogs_nometrics
| where EventProcessedUtcTime >= ago(5m)
| count;
--    Si count = 0, el problema estÃ¡ en la ingesta (Event Hub/Stream Analytics)
--    Si count > 0, el problema estÃ¡ en las queries (revisar thresholds)


-- ğŸš¨ PROBLEMA: AnomalÃ­as aparecen pero sin detalles (User/Database/Host vacÃ­os)
-- ğŸ”§ SOLUCIÃ“N: Revisar correlaciÃ³n sessionInfo

-- Ejecutar query de diagnÃ³stico en KQL Database:
let sessionInfo = 
bronze_pssql_alllogs_nometrics
| where EventProcessedUtcTime >= ago(24h)
| where message contains "connection authorized" or message contains "connection received"
| extend 
    UserName = extract(@"user=([^\s,]+)", 1, message),
    DatabaseName = extract(@"database=([^\s,]+)", 1, message),
    ClientHost = extract(@"host=([^\s]+)", 1, message)
| where isnotempty(UserName)
| summarize User = any(UserName), Database = any(DatabaseName), SourceHost = any(ClientHost)
    by processId, LogicalServerName;

sessionInfo
| count;
-- Si count = 0, NO hay CONNECTION logs en la tabla (verificar Diagnostic Settings)
-- Si count > 0, la correlaciÃ³n deberÃ­a funcionar (verificar que processId coincide)


-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
-- 5. PUNTOS CLAVE PARA EXPLICAR AL CLIENTE (SCRIPT DE DEMO)
-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

-- ğŸ¯ MENSAJE 1: "DetecciÃ³n en Tiempo Real"
-- - "Los logs de PostgreSQL llegan a Fabric en 30-90 segundos"
-- - "No hay necesidad de consultar directamente PostgreSQL"
-- - "Todo se procesa en Fabric con KQL (lenguaje Azure Data Explorer)"

-- ğŸ¯ MENSAJE 2: "CorrelaciÃ³n User/Database/Host"
-- - "PostgreSQL AUDIT logs NO incluyen usuario por defecto"
-- - "Correlacionamos con CONNECTION logs usando processId"
-- - "Esto permite identificar QUIÃ‰N hizo QUÃ‰ desde DÃ“NDE"

-- ğŸ¯ MENSAJE 3: "Thresholds Ajustables"
-- - "AnomalÃ­a 1: >15 SELECTs en 5 min (ajustable segÃºn tu baseline)"
-- - "AnomalÃ­a 2: >5 operaciones destructivas en 2 min (ventanas bin(2m))"
-- - "AnomalÃ­a 3: >15 errores por minuto (muy conservador)"
-- - "Puedes modificar los thresholds en kql-queries-PRODUCTION.kql"

-- ğŸ¯ MENSAJE 4: "Alertas AutomÃ¡ticas"
-- - "Data Activator monitorea las anomalÃ­as cada 1-2 minutos"
-- - "Si se superan los thresholds, dispara alertas instantÃ¡neas"
-- - "EnvÃ­a emails/Teams con toda la informaciÃ³n contextual"
-- - "Puede integrar con ServiceNow/Jira para crear tickets automÃ¡ticamente"

-- ğŸ¯ MENSAJE 5: "Sin Agentes, Sin Impacto"
-- - "No requiere instalar nada en PostgreSQL"
-- - "Solo requiere pgaudit (extensiÃ³n nativa de PostgreSQL)"
-- - "Impacto en performance: <1% (logging asÃ­ncrono)"
-- - "Escalable a cientos de servidores PostgreSQL"


-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
-- 6. CHECKLIST FINAL ANTES DE LA DEMO CON CLIENTE
-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

-- â˜ 1. Verificar pgaudit instalado y configurado (pgaudit.log = 'ALL')
-- â˜ 2. Verificar Diagnostic Settings enviando logs a Event Hub
-- â˜ 3. Verificar Event Stream ingiriendo datos a KQL Database
-- â˜ 4. Verificar tabla bronze_pssql_alllogs_nometrics tiene datos recientes (<5 min)
-- â˜ 5. Verificar dashboard creado con queries de kql-queries-PRODUCTION.kql
-- â˜ 6. (Opcional) Verificar alertas configuradas en Data Activator
-- â˜ 7. Ejecutar TEST 1 y verificar que aparece en dashboard (~2 min)
-- â˜ 8. Ejecutar TEST 2 y verificar que aparece en dashboard (~2 min)
-- â˜ 9. Ejecutar TEST 3 y verificar que aparece en dashboard (~2 min)
-- â˜ 10. Ejecutar TEST 4 (Privilege Escalation) y verificar (~2 min)
-- â˜ 11. Ejecutar TEST 5 (Cross-Schema Recon) y verificar (~2 min)
-- â˜ 12. Ejecutar TEST 6 (Deep Schema Enum) y verificar (~2 min)
-- â˜ 13. Ejecutar TEST 7 (ML Baseline) y verificar (~5-10 min)
-- â˜ 14. (Opcional) Ejecutar TEST AUTH con script bash/powershell/python
-- â˜ 15. Verificar que User/Database/Host NO son "UNKNOWN" (correlaciÃ³n OK)
-- â˜ 16. Limpiar tabla temp_test_anomaly al final de la demo

-- âœ… SI TODOS LOS CHECKS PASAN, ESTÃS LISTO PARA LA DEMO!
-- ============================================================================


-- ============================================================================
-- NOTAS ADICIONALES - INFORMACIÃ“N TÃ‰CNICA
-- ============================================================================

-- ğŸ“Œ THRESHOLDS ACTUALES (Configurados en kql-queries-PRODUCTION.kql):
-- â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
-- â”‚ ANOMALÃA 1 - Data Exfiltration:                                        â”‚
-- â”‚   - Threshold: SelectCount > 15 (en 5 minutos)                         â”‚
-- â”‚   - Ventana: ago(5m)                                                   â”‚
-- â”‚   - Filtro: backend_type == "client backend" (solo usuarios reales)    â”‚
-- â”‚   - Query: LÃ­neas 26-70 de kql-queries-PRODUCTION.kql                  â”‚
-- â”‚                                                                         â”‚
-- â”‚ ANOMALÃA 2 - Mass Destructive Operations:                              â”‚
-- â”‚   - Threshold: OperationCount > 5 (en ventanas de 2 minutos)           â”‚
-- â”‚   - Ventana: ago(10m) con bin(EventProcessedUtcTime, 2m)               â”‚
-- â”‚   - Filtro: backend_type == "client backend" (aplicado POST-threshold) â”‚
-- â”‚   - Query: LÃ­neas 76-122 de kql-queries-PRODUCTION.kql                 â”‚
-- â”‚                                                                         â”‚
-- â”‚ ANOMALÃA 3 - Critical Error Spike:                                     â”‚
-- â”‚   - Threshold: ErrorCount > 15 (por minuto)                            â”‚
-- â”‚   - Ventana: ago(5m) con bin(EventProcessedUtcTime, 1m)                â”‚
-- â”‚   - Filtro: errorLevel in ("ERROR", "FATAL", "PANIC")                  â”‚
-- â”‚   - Query: LÃ­neas 128-184 de kql-queries-PRODUCTION.kql                â”‚
-- â”‚                                                                         â”‚
-- â”‚ TILE - Authentication Failures:                                        â”‚
-- â”‚   - Threshold: FailedAttempts > 3 (por usuario/host en 24h)            â”‚
-- â”‚   - Ventana: ago(24h)                                                  â”‚
-- â”‚   - ThreatLevel: >3 = HIGH, >10 = CRITICAL                             â”‚
-- â”‚   - Query: LÃ­neas 424-445 de kql-queries-PRODUCTION.kql                â”‚
-- â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

-- ğŸ”§ CÃ“MO AJUSTAR THRESHOLDS (Post-demo con el cliente):
-- 1. Abre el archivo: queries/kql-queries-PRODUCTION.kql
-- 2. Busca la lÃ­nea con "| where SelectCount > 15" (para AnomalÃ­a 1)
-- 3. Cambia el valor 15 por el threshold que desees (ej: 20, 30, etc.)
-- 4. Repite para las otras anomalÃ­as (OperationCount > 5, ErrorCount > 15)
-- 5. Actualiza el dashboard en Fabric con la query modificada
-- 6. (Opcional) Actualiza las alertas en Data Activator con el nuevo threshold


-- ğŸ“Š REQUISITOS DE DATOS (Para que las anomalÃ­as funcionen):
-- â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
-- â”‚ âœ… ExtensiÃ³n pgaudit instalada en PostgreSQL:                          â”‚
-- â”‚    CREATE EXTENSION IF NOT EXISTS pgaudit;                             â”‚
-- â”‚                                                                         â”‚
-- â”‚ âœ… ConfiguraciÃ³n pgaudit en PostgreSQL (Azure Portal):                 â”‚
-- â”‚    Server Parameters â†’ pgaudit.log â†’ Valor: 'ALL'                      â”‚
-- â”‚    Server Parameters â†’ shared_preload_libraries â†’ Valor: 'pgaudit'     â”‚
-- â”‚    Server Parameters â†’ azure.extensions â†’ Valor: 'PGAUDIT' (allowlist) â”‚
-- â”‚                                                                         â”‚
-- â”‚ âœ… Diagnostic Settings habilitado (Azure Portal):                      â”‚
-- â”‚    PostgreSQL Flexible Server â†’ Diagnostic Settings                    â”‚
-- â”‚    â†’ Logs: PostgreSQLLogs (checked)                                    â”‚
-- â”‚    â†’ Destination: Event Hub (configurar nombre)                        â”‚
-- â”‚                                                                         â”‚
-- â”‚ âœ… Event Stream configurado en Fabric:                                 â”‚
-- â”‚    Source: Event Hub (con los logs de PostgreSQL)                      â”‚
-- â”‚    Destination: KQL Database â†’ Tabla: bronze_pssql_alllogs_nometrics   â”‚
-- â”‚                                                                         â”‚
-- â”‚ âœ… Tabla KQL Database con datos recientes:                             â”‚
-- â”‚    Verificar: bronze_pssql_alllogs_nometrics                           â”‚
-- â”‚    | where EventProcessedUtcTime >= ago(5m) | count;                   â”‚
-- â”‚    Debe retornar count > 0 (si = 0, verificar Event Stream)            â”‚
-- â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


-- ğŸ¯ VENTAJAS DE ESTA SOLUCIÃ“N (Puntos de venta para el cliente):
-- â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
-- â”‚ 1. SIN AGENTES: No requiere instalar software adicional en servidores  â”‚
-- â”‚    - Solo usa extensiÃ³n nativa de PostgreSQL (pgaudit)                  â”‚
-- â”‚    - No consume CPU/memoria del servidor de base de datos              â”‚
-- â”‚                                                                         â”‚
-- â”‚ 2. TIEMPO REAL: DetecciÃ³n en 30-90 segundos                            â”‚
-- â”‚    - Logs fluyen automÃ¡ticamente a Fabric vÃ­a Event Hub                â”‚
-- â”‚    - Procesamiento continuo con Stream Analytics                       â”‚
-- â”‚    - Alertas instantÃ¡neas con Data Activator                           â”‚
-- â”‚                                                                         â”‚
-- â”‚ 3. ESCALABLE: Funciona con cientos de servidores PostgreSQL            â”‚
-- â”‚    - Todos los servidores envÃ­an logs al mismo Event Hub               â”‚
-- â”‚    - KQL Database maneja millones de eventos por dÃ­a                   â”‚
-- â”‚    - Queries optimizadas para grandes volÃºmenes de datos               â”‚
-- â”‚                                                                         â”‚
-- â”‚ 4. SIN CÃ“DIGO: ConfiguraciÃ³n point-and-click                           â”‚
-- â”‚    - Diagnostic Settings: 3 clicks en Azure Portal                     â”‚
-- â”‚    - Event Stream: ConfiguraciÃ³n visual en Fabric                      â”‚
-- â”‚    - Dashboard: Copy/paste queries KQL                                 â”‚
-- â”‚    - Alertas: ConfiguraciÃ³n visual en Data Activator                   â”‚
-- â”‚                                                                         â”‚
-- â”‚ 5. INTEGRABLE: ConexiÃ³n con herramientas existentes                    â”‚
-- â”‚    - Emails automÃ¡ticos (Exchange, Gmail, etc.)                        â”‚
-- â”‚    - Microsoft Teams notifications                                     â”‚
-- â”‚    - ServiceNow/Jira ticketing (vÃ­a Power Automate)                    â”‚
-- â”‚    - SIEM integration (Sentinel, Splunk, etc.)                         â”‚
-- â”‚                                                                         â”‚
-- â”‚ 6. COSTO-EFECTIVO: Parte de tu licencia Microsoft Fabric               â”‚
-- â”‚    - No requiere licencias adicionales de SIEM/monitoring              â”‚
-- â”‚    - Pricing basado en consumo (pay-as-you-go)                         â”‚
-- â”‚    - Rentable incluso para pequeÃ±as implementaciones                   â”‚
-- â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


-- ğŸ” CASOS DE USO REALES (Ejemplos para mostrar al cliente):
-- â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
-- â”‚ CASO 1: Insider Threat Detection                                       â”‚
-- â”‚ - Empleado malicioso ejecuta 50 SELECTs para robar datos de clientes  â”‚
-- â”‚ - AnomalÃ­a 1 detecta actividad en 2 minutos                            â”‚
-- â”‚ - Alerta enviada a Security Team vÃ­a Teams                             â”‚
-- â”‚ - Se bloquea cuenta del empleado antes de exfiltrar datos              â”‚
-- â”‚                                                                         â”‚
-- â”‚ CASO 2: Ransomware Attack Prevention                                   â”‚
-- â”‚ - Ransomware intenta ejecutar DELETE masivo en tablas crÃ­ticas         â”‚
-- â”‚ - AnomalÃ­a 2 detecta 10 DELETEs en 1 minuto                            â”‚
-- â”‚ - Alerta crÃ­tica enviada a DBA Team                                    â”‚
-- â”‚ - DBA hace rollback desde backup antes de pÃ©rdida total                â”‚
-- â”‚                                                                         â”‚
-- â”‚ CASO 3: SQL Injection Detection                                        â”‚
-- â”‚ - Atacante externo intenta SQL injection en aplicaciÃ³n web             â”‚
-- â”‚ - Genera 30 errores de sintaxis en 30 segundos                         â”‚
-- â”‚ - AnomalÃ­a 3 detecta error spike                                       â”‚
-- â”‚ - IP del atacante bloqueada en firewall automÃ¡ticamente                â”‚
-- â”‚                                                                         â”‚
-- â”‚ CASO 4: Brute Force Attack Detection                                   â”‚
-- â”‚ - Botnet intenta 100 contraseÃ±as en 5 minutos                          â”‚
-- â”‚ - TILE "Auth Failures" detecta 100 fallos desde misma IP               â”‚
-- â”‚ - IP agregada a blacklist de NSG automÃ¡ticamente                       â”‚
-- â”‚ - Cuenta de usuario bloqueada preventivamente                          â”‚
-- â”‚                                                                         â”‚
-- â”‚ CASO 5: Misconfiguration Detection                                     â”‚
-- â”‚ - AplicaciÃ³n con connection string incorrecta genera 500 errores/min   â”‚
-- â”‚ - AnomalÃ­a 3 detecta error spike                                       â”‚
-- â”‚ - Alerta enviada a Dev Team con detalles del error                     â”‚
-- â”‚ - Dev Team corrige configuraciÃ³n en 5 minutos (vs horas de downtime)   â”‚
-- â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


-- ğŸ“š RECURSOS ADICIONALES (Para entregar al cliente post-demo):
-- â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
-- â”‚ ğŸ“„ DocumentaciÃ³n del Proyecto:                                         â”‚
-- â”‚    - README.md: VisiÃ³n general del proyecto                            â”‚
-- â”‚    - docs/QUICKSTART.md: GuÃ­a de inicio rÃ¡pido (5 min setup)           â”‚
-- â”‚    - docs/DEPLOYMENT-CHECKLIST.md: Lista de verificaciÃ³n completa      â”‚
-- â”‚    - docs/DASHBOARD-SETUP-GUIDE.md: Configurar dashboard paso a paso   â”‚
-- â”‚    - docs/REFLEX-ALERTS-CONFIG.md: Configurar alertas en Data Activatorâ”‚
-- â”‚    - docs/ALERTAS-QUERIES-ESPECIFICAS.md: Queries completas para alertsâ”‚
-- â”‚                                                                         â”‚
-- â”‚ ğŸ“Š Queries KQL:                                                        â”‚
-- â”‚    - queries/kql-queries-PRODUCTION.kql: Queries de dashboard (main)   â”‚
-- â”‚    - queries/kql-queries-ENHANCED.kql: Queries avanzadas (opcional)    â”‚
-- â”‚    - queries/DEBUG-AUDIT-FORMAT.kql: Debugging pgaudit config          â”‚
-- â”‚    - queries/DIAGNOSTIC-AUDIT-CONFIG.kql: Validar configuraciÃ³n        â”‚
-- â”‚                                                                         â”‚
-- â”‚ ğŸ§ª Scripts de Testing:                                                 â”‚
-- â”‚    - TEST-ANOMALY-TRIGGERS.sql: Este archivo (generar anomalÃ­as)       â”‚
-- â”‚    - queries/TEST-USER-DATABASE-IP.kql: Validar correlaciÃ³n            â”‚
-- â”‚                                                                         â”‚
-- â”‚ ğŸ”— Links Ãštiles:                                                       â”‚
-- â”‚    - pgaudit docs: https://github.com/pgaudit/pgaudit                  â”‚
-- â”‚    - Azure PostgreSQL: https://learn.microsoft.com/azure/postgresql    â”‚
-- â”‚    - Microsoft Fabric: https://learn.microsoft.com/fabric              â”‚
-- â”‚    - KQL reference: https://learn.microsoft.com/azure/data-explorer/kqlâ”‚
-- â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


-- ğŸ“ PRÃ“XIMOS PASOS POST-DEMO (Recomendaciones para el cliente):
-- â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
-- â”‚ 1. IMPLEMENTACIÃ“N INICIAL (Semana 1):                                  â”‚
-- â”‚    â˜ Habilitar pgaudit en servidor de prueba/staging                   â”‚
-- â”‚    â˜ Configurar Diagnostic Settings â†’ Event Hub                        â”‚
-- â”‚    â˜ Crear Event Stream en Fabric                                      â”‚
-- â”‚    â˜ Validar ingesta de datos (tabla bronze_pssql_alllogs_nometrics)   â”‚
-- â”‚                                                                         â”‚
-- â”‚ 2. CONFIGURACIÃ“N DE DASHBOARD (Semana 1-2):                            â”‚
-- â”‚    â˜ Crear dashboard con queries de kql-queries-PRODUCTION.kql         â”‚
-- â”‚    â˜ Ejecutar tests de anomalÃ­as para validar funcionamiento           â”‚
-- â”‚    â˜ Ajustar thresholds segÃºn baseline de tu entorno                   â”‚
-- â”‚    â˜ Compartir dashboard con equipos de seguridad/DBA/DevOps           â”‚
-- â”‚                                                                         â”‚
-- â”‚ 3. CONFIGURACIÃ“N DE ALERTAS (Semana 2-3):                              â”‚
-- â”‚    â˜ Configurar alertas en Data Activator para las 3 anomalÃ­as         â”‚
-- â”‚    â˜ Definir destinatarios: Security, DBA, DevOps teams                â”‚
-- â”‚    â˜ Configurar canales de Teams para notificaciones                   â”‚
-- â”‚    â˜ (Opcional) Integrar con ServiceNow/Jira para ticketing            â”‚
-- â”‚                                                                         â”‚
-- â”‚ 4. REFINAMIENTO (Semana 3-4):                                          â”‚
-- â”‚    â˜ Analizar falsos positivos y ajustar thresholds                    â”‚
-- â”‚    â˜ Crear tabla UserContext/HostContext para enriquecer alertas       â”‚
-- â”‚    â˜ Configurar whitelist de IPs/usuarios conocidos                    â”‚
-- â”‚    â˜ Documentar runbooks de respuesta a incidentes                     â”‚
-- â”‚                                                                         â”‚
-- â”‚ 5. ROLLOUT A PRODUCCIÃ“N (Semana 4+):                                   â”‚
-- â”‚    â˜ Habilitar pgaudit en servidores de producciÃ³n (uno a la vez)      â”‚
-- â”‚    â˜ Monitorear impacto en performance (<1% esperado)                  â”‚
-- â”‚    â˜ Validar que todas las anomalÃ­as se detectan correctamente         â”‚
-- â”‚    â˜ Entrenar equipos en uso del dashboard y respuesta a alertas       â”‚
-- â”‚                                                                         â”‚
-- â”‚ 6. MANTENIMIENTO CONTINUO (Mensual):                                   â”‚
-- â”‚    â˜ Revisar anomalÃ­as detectadas y validar si fueron verdaderos       â”‚
-- â”‚    â˜ Ajustar thresholds basados en patrones reales de uso              â”‚
-- â”‚    â˜ Agregar nuevas anomalÃ­as segÃºn necesidades del negocio            â”‚
-- â”‚    â˜ Revisar logs de alertas y optimizar canales de notificaciÃ³n       â”‚
-- â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

-- ============================================================================
-- FIN DEL SCRIPT DE PRUEBA
-- ============================================================================
